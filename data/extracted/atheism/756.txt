The Atlantic

  • Subscribe
  • Search
  • Menu

The Biological Basis of Morality

  •  
  •  
  •  

[                    ]
Close

  • Home
  • Latest
  • Most Popular
  • Magazine
  • Video
  • Photo
  • Writers

  • News
  • Politics
  • Business
  • Culture
  • Science
  • Technology
  • Health
  • Sexes
  • U.S.
  • Education
  • Global

  • Notes
  • Projects
  • Events
  • Books
  • Shop

  • Your AccountSign Out
  • Sign InSign Up

 

2 Free Issues

Try two trial issues of The Atlantic with our compliments.

Claim now

Follow

  • Facebook
  • Twitter
  • LinkedIn
  • Tumblr
  • Pinterest
  • RSS
  • App Store

See our Newsletters >
previousThe Relevancy StandardThe Trouble With Single-Sex Schoolsnext story

The Biological Basis of Morality

Do we invent our moral absolutes in order to make society workable? Or are
these enduring principles expressed to us by some transcendent or Godlike
authority? Efforts to resolve this conundrum have perplexed, sometimes
inflamed, our best minds for centuries, but the natural sciences are telling us
more and more about the choices we make and our reasons for making them

We noticed that you have an
AD BLOCKER
ENABLED

Please consider disabling it for our site, or supporting our work in one of
these ways
 
[large] [large]
Subscribe Now >
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
Sign up for
The Atlantic Daily newsletter

[*] I want to receive updates from partners and sponsors.

[Sign up]

  • 
     
  • 
     
  •  
  •  
  •   
  •  
  •  
  •  

  • Edward O. Wilson
  • April 1998 Issue

 The online version of this article appears in two parts. Click here to go to 
                                   part two.




CENTURIES of debate on the origin of ethics come down to this: Either ethical
principles, such as justice and human rights, are independent of human
experience, or they are human inventions. The distinction is more than an
exercise for academic philosophers. The choice between these two understandings
makes all the difference in the way we view ourselves as a species. It measures
the authority of religion, and it determines the conduct of moral reasoning.

The two assumptions in competition are like islands in a sea of chaos, as
different as life and death, matter and the void. One cannot learn which is
correct by pure logic; the answer will eventually be reached through an
accumulation of objective evidence. Moral reasoning, I believe, is at every
level intrinsically consilient with -- compatible with, intertwined with -- the
natural sciences. (I use a form of the word "consilience" -- literally a
"jumping together" of knowledge as a result of the linking of facts and
fact-based theory across disciplines to create a common groundwork of
explanation -- because its rarity has preserved its precision.)


Every thoughtful person has an opinion on which premise is correct. But the
split is not, as popularly supposed, between religious believers and
secularists. It is between transcendentalists, who think that moral guidelines
exist outside the human mind, and empiricists, who think them contrivances of
the mind. In simplest terms, the options are as follows: I believe in the
independence of moral values, whether from God or not, and I believe that moral
values come from human beings alone, whether or not God exists.

Theologians and philosophers have almost always focused on transcendentalism as
the means to validate ethics. They seek the grail of natural law, which
comprises freestanding principles of moral conduct immune to doubt and
compromise. Christian theologians, following Saint Thomas Aquinas's reasoning
in Summa Theologiae, by and large consider natural law to be an expression of
God's will. In this view, human beings have an obligation to discover the law
by diligent reasoning and to weave it into the routine of their daily lives.
Secular philosophers of a transcendental bent may seem to be radically
different from theologians, but they are actually quite similar, at least in
moral reasoning. They tend to view natural law as a set of principles so
powerful, whatever their origin, as to be self-evident to any rational person.
In short, transcendental views are fundamentally the same whether God is
invoked or not.

For example, when Thomas Jefferson, following John Locke, derived the doctrine
of natural rights from natural law, he was more concerned with the power of
transcendental statements than with their origin, divine or secular. In the
Declaration of Independence he blended secular and religious presumptions in
one transcendentalist sentence, thus deftly covering all bets: "We hold these
Truths to be self-evident, that all Men are created equal, that they are
endowed by their Creator with certain unalienable Rights, that among these are
Life, Liberty, and the Pursuit of Happiness." That assertion became the
cardinal premise of America's civil religion, the righteous sword wielded by
Abraham Lincoln and Martin Luther King Jr., and it endures as the central ethic
binding together the diverse peoples of the United States.

So compelling are such fruits of natural-law theory, especially when the Deity
is also invoked, that they may seem to place the transcendentalist assumption
beyond question. But to its noble successes must be added appalling failures.
It has been perverted many times in the past -- used, for example, to argue
passionately for colonial conquest, slavery, and genocide. Nor was any great
war ever fought without each side thinking its cause transcendentally sacred in
some manner or other.

So perhaps we need to take empiricism more seriously. In the empiricist view,
ethics is conduct favored consistently enough throughout a society to be
expressed as a code of principles. It reaches its precise form in each culture
according to historical circumstance. The codes, whether adjudged good or evil
by outsiders, play an important role in determining which cultures flourish and
which decline.

The crux of the empiricist view is its emphasis on objective knowledge. Because
the success of an ethical code depends on how wisely it interprets moral
sentiments, those who frame one should know how the brain works, and how the
mind develops. The success of ethics also depends on how accurately a society
can predict the consequences of particular actions as opposed to others,
especially in cases of moral ambiguity.

The empiricist argument holds that if we explore the biological roots of moral
behavior, and explain their material origins and biases, we should be able to
fashion a wise and enduring ethical consensus. The current expansion of
scientific inquiry into the deeper processes of human thought makes this
venture feasible.

The choice between transcendentalism and empiricism will be the coming
century's version of the struggle for men's souls. Moral reasoning will either
remain centered in idioms of theology and philosophy, where it is now, or shift
toward science-based material analysis. Where it settles will depend on which
world view is proved correct, or at least which is more widely perceived to be
correct.

Ethicists, scholars who specialize in moral reasoning, tend not to declare
themselves on the foundations of ethics, or to admit fallibility. Rarely do we
see an argument that opens with the simple statement This is my starting point,
and it could be wrong. Ethicists instead favor a fretful passage from the
particular to the ambiguous, or the reverse -- vagueness into hard cases. I
suspect that almost all are transcendentalists at heart, but they rarely say so
in simple declarative sentences. One cannot blame them very much; explaining
the ineffable is difficult.

I am an empiricist. On religion I lean toward deism, but consider its proof
largely a problem in astrophysics. The existence of a God who created the
universe (as envisioned by deism) is possible, and the question may eventually
be settled, perhaps by forms of material evidence not yet imagined. Or the
matter may be forever beyond human reach. In contrast, and of far greater
importance to humanity, the idea of a biological God, one who directs organic
evolution and intervenes in human affairs (as envisioned by theism), is
increasingly contravened by biology and the brain sciences.

The same evidence, I believe, favors a purely material origin of ethics, and it
meets the criterion of consilience: causal explanations of brain activity and
evolution, while imperfect, already cover most facts known about behavior we
term "moral." Although this conception is relativistic (in other words,
dependent on personal viewpoint), it can, if evolved carefully, lead more
directly and safely to stable moral codes than can transcendentalism, which is
also, when one thinks about it, ultimately relativistic.

Of course, lest I forget, I may be wrong.

                      Transcendentalism Versus Empiricism


THE argument of the empiricist has roots that go back to Aristotle's
Nicomachean Ethics and, in the beginning of the modern era, to David Hume's A
Treatise of Human Nature (1739-1740). The first clear evolutionary elaboration
of it was by Charles Darwin, in The Descent of Man (1871).

Again, religious transcendentalism is bolstered by secular transcendentalism,
to which it is fundamentally similar. Immanuel Kant, judged by history the
greatest of secular philosophers, addressed moral reasoning very much as a
theologian. Human beings, he argued, are independent moral agents with a wholly
free will, capable of obeying or breaking moral law: "There is in man a power
of self-determination, independent of any coercion through sensuous impulses."
Our minds are subject to a categorical imperative, Kant said, of what our
actions ought to be. The imperative is a good in itself alone, apart from all
other considerations, and it can be recognized by this rule: "Act only on that
maxim you wish will become a universal law." Most important, and
transcendental, ought has no place in nature. Nature, Kant said, is a system of
cause and effect, whereas moral choice is a matter of free will, absent cause
and effect. In making moral choices, in rising above mere instinct, human
beings transcend the realm of nature and enter a realm of freedom that belongs
exclusively to them as rational creatures.

Now, this formulation has a comforting feel to it, but it makes no sense at all
in terms of either material or imaginable entities, which is why Kant, even
apart from his tortured prose, is so hard to understand. Sometimes a concept is
baffling not because it is profound but because it is wrong. This idea does not
accord, we know now, with the evidence of how the brain works.

In Principia Ethica (1903), G. E. Moore, the founder of modern ethical
philosophy, essentially agreed with Kant. In his view, moral reasoning cannot
dip into psychology and the social sciences in order to locate ethical
principles, because those disciplines yield only a causal picture and fail to
illuminate the basis of moral justification. So to reach the normative ought by
way of the factual is is to commit a basic error of logic, which Moore called
the naturalistic fallacy. John Rawls, in A Theory of Justice (1971), once again
traveled the transcendental road. He offered the very plausible suggestion that
justice be defined as fairness, which is to be accepted as an intrinsic good.
It is the imperative we would follow if we had no starting information about
our own future status in life. But in making such a suggestion Rawls ventured
no thought on where the human brain comes from or how it works. He offered no
evidence that justice-as-fairness is consistent with human nature, hence
practicable as a blanket premise. Probably it is, but how can we know except by
blind trial and error?

Had Kant, Moore, and Rawls known modern biology and experimental psychology,
they might well not have reasoned as they did. Yet as this century closes,
transcendentalism remains firm in the hearts not just of religious believers
but also of countless scholars in the social sciences and the humanities who,
like Moore and Rawls, have chosen to insulate their thinking from the natural
sciences.

Many philosophers will respond by saying, Ethicists don't need that kind of
information. You really can't pass from is to ought. You can't describe a
genetic predisposition and suppose that because it is part of human nature, it
is somehow transformed into an ethical precept. We must put moral reasoning in
a special category, and use transcendental guidelines as required.

No, we do not have to put moral reasoning in a special category and use
transcendental premises, because the posing of the naturalistic fallacy is
itself a fallacy. For if ought is not is, what is? To translate is into ought
makes sense if we attend to the objective meaning of ethical precepts. They are
very unlikely to be ethereal messages awaiting revelation, or independent
truths vibrating in a nonmaterial dimension of the mind. They are more likely
to be products of the brain and the culture. From the consilient perspective of
the natural sciences, they are no more than principles of the social contract
hardened into rules and dictates -- the behavioral codes that members of a
society fervently wish others to follow and are themselves willing to accept
for the common good. Precepts are the extreme on a scale of agreements that
range from casual assent, to public sentiment, to law, to that part of the
canon considered sacred and unalterable. The scale applied to adultery might
read as follows:

In transcendental thinking, the chain of causation runs downward from the given
ought in religion or natural law through jurisprudence to education and finally
to individual choice. The argument from transcendentalism takes the following
general form: The order of nature contains supreme principles, either divine or
intrinsic, and we will be wise to learn about them and find the means to
conform to them. Thus John Rawls opens A Theory of Justice with a proposition
he regards as irrevocable: "In a just society the liberties of equal
citizenship are taken as settled; the rights secured by justice are not subject
to political bargaining or to the calculus of social interests." As many
critiques have made clear, that premise can lead to unhappy consequences when
applied to the real world, including a tightening of social control and a
decline in personal initiative. A very different premise, therefore, is
suggested by Robert Nozick in Anarchy, State, and Utopia (1974): "Individuals
have rights, and there are things no person or group may do to them (without
violating their rights). So strong and far-reaching are these rights that they
raise the question of what, if anything, the state and its officials may do."
Rawls would point us toward egalitarianism regulated by the state, Nozick
toward libertarianism in a minimalist state.

The empiricist view, in contrast, searching for an origin of ethical reasoning
that can be objectively studied, reverses the chain of causation. The
individual is seen as predisposed biologically to make certain choices. Through
cultural evolution some of the choices are hardened into precepts, then into
laws, and, if the predisposition or coercion is strong enough, into a belief in
the command of God or the natural order of the universe. The general empiricist
principle takes this form: Strong innate feeling and historical experience
cause certain actions to be preferred; we have experienced them, and have
weighed their consequences, and agree to conform with codes that express them.
Let us take an oath upon the codes, invest our personal honor in them, and
suffer punishment for their violation. The empiricist view concedes that moral
codes are devised to conform to some drives of human nature and to suppress
others. Ought is the translation not of human nature but of the public will,
which can be made increasingly wise and stable through an understanding of the
needs and pitfalls of human nature. The empiricist view recognizes that the
strength of commitment can wane as a result of new knowledge and experience,
with the result that certain rules may be desacralized, old laws rescinded, and
formerly prohibited behavior set free. It also recognizes that for the same
reason new moral codes may need to be devised, with the potential of being made
sacred in time.

                         The Origin of Moral Instincts


IF the empiricist world view is correct, ought is just shorthand for one kind
of factual statement, a word that denotes what society first chose (or was
coerced) to do, and then codified. The naturalistic fallacy is thereby reduced
to the naturalistic problem. The solution of the problem is not difficult:
ought is the product of a material process. The solution points the way to an
objective grasp of the origin of ethics.

A few investigators are now embarked on just such a foundational inquiry. Most
agree that ethical codes have arisen by evolution through the interplay of
biology and culture. In a sense these investigators are reviving the idea of
moral sentiments that was developed in the eighteenth century by the British
empiricists Francis Hutcheson, David Hume, and Adam Smith.

What have been thought of as moral sentiments are now taken to mean moral
instincts (as defined by the modern behavioral sciences), subject to judgment
according to their consequences. Such sentiments are thus derived from
epigenetic rules -- hereditary biases in mental development, usually
conditioned by emotion, that influence concepts and decisions made from them.
The primary origin of moral instincts is the dynamic relation between
cooperation and defection. The essential ingredient for the molding of the
instincts during genetic evolution in any species is intelligence high enough
to judge and manipulate the tension generated by the dynamism. That level of
intelligence allows the building of complex mental scenarios well into the
future. It occurs, so far as is known, only in human beings and perhaps their
closest relatives among the higher apes.

A way of envisioning the hypothetical earliest stages of moral evolution is
provided by game theory, particularly the solutions to the famous Prisoner's
Dilemma. Consider the following typical scenario of the dilemma. Two gang
members have been arrested for murder and are being questioned separately. The
evidence against them is strong but not irrefutable. The first gang member
believes that if he turns state's witness, he will be granted immunity and his
partner will be sentenced to life in prison. But he is also aware that his
partner has the same option, and that if both of them exercise it, neither will
be granted immunity. That is the dilemma. Will the two gang members
independently defect, so that both take the hard fall? They will not, because
they agreed in advance to remain silent if caught. By doing so, both hope to be
convicted on a lesser charge or escape punishment altogether. Criminal gangs
have turned this principle of calculation into an ethical precept: Never rat on
another member; always be a stand-up guy. Honor does exist among thieves. The
gang is a society of sorts; its code is the same as that of a captive soldier
in wartime, obliged to give only name, rank, and serial number.

In one form or another, comparable dilemmas that are solvable by cooperation
occur constantly and everywhere in daily life. The payoff is variously money,
status, power, sex, access, comfort, or health. Most of these proximate rewards
are converted into the universal bottom line of Darwinian genetic fitness:
greater longevity and a secure, growing family.

And so it has most likely always been. Imagine a Paleolithic band of five
hunters. One considers breaking away from the others to look for an antelope on
his own. If successful, he will gain a large quantity of meat and hide -- five
times as much as if he stays with the band and they are successful. But he
knows from experience that his chances of success are very low, much less than
the chances of the band of five working together. In addition, whether
successful alone or not, he will suffer animosity from the others for lessening
their prospects. By custom the band members remain together and share equitably
the animals they kill. So the hunter stays. He also observes good manners in
doing so, especially if he is the one who makes the kill. Boastful pride is
condemned, because it rips the delicate web of reciprocity.

Now suppose that human propensities to cooperate or defect are heritable: some
people are innately more cooperative, others less so. In this respect moral
aptitude would simply be like almost all other mental traits studied to date.
Among traits with documented heritability, those closest to moral aptitude are
empathy with the distress of others and certain processes of attachment between
infants and their caregivers. To the heritability of moral aptitude add the
abundant evidence of history that cooperative individuals generally survive
longer and leave more offspring. Following that reasoning, in the course of
evolutionary history genes predisposing people toward cooperative behavior
would have come to predominate in the human population as a whole.

Such a process repeated through thousands of generations inevitably gave rise
to moral sentiments. With the exception of psychopaths (if any truly exist),
every person vividly experiences these instincts variously as conscience,
self-respect, remorse, empathy, shame, humility, and moral outrage. They bias
cultural evolution toward the conventions that express the universal moral
codes of honor, patriotism, altruism, justice, compassion, mercy, and
redemption.

The dark side of the inborn propensity to moral behavior is xenophobia. Because
personal familiarity and common interest are vital in social transactions,
moral sentiments evolved to be selective. People give trust to strangers with
effort, and true compassion is a commodity in chronically short supply. Tribes
cooperate only through carefully defined treaties and other conventions. They
are quick to imagine themselves the victims of conspiracies by competing
groups, and they are prone to dehumanize and murder their rivals during periods
of severe conflict. They cement their own group loyalties by means of sacred
symbols and ceremonies. Their mythologies are filled with epic victories over
menacing enemies.

The complementary instincts of morality and tribalism are easily manipulated.
Civilization has made them more so. Beginning about 10,000 years ago, a tick in
geological time, when the agricultural revolution started in the Middle East,
in China, and in Mesoamerica, populations increased tenfold in density over
those of hunter-gatherer societies. Families settled on small plots of land,
villages proliferated, and labor was finely divided as a growing minority of
the populace specialized as craftsmen, traders, and soldiers. The rising
agricultural societies became increasingly hierarchical. As chiefdoms and then
states thrived on agricultural surpluses, hereditary rulers and priestly castes
took power. The old ethical codes were transformed into coercive regulations,
always to the advantage of the ruling classes. About this time the idea of
law-giving gods originated. Their commands lent the ethical codes overpowering
authority -- once again, no surprise, in the interests of the rulers.

Because of the technical difficulty of analyzing such phenomena in an objective
manner, and because people resist biological explanations of their higher
cortical functions in the first place, very little progress has been made in
the biological exploration of the moral sentiments. Even so, it is astonishing
that the study of ethics has advanced so little since the nineteenth century.
The most distinguishing and vital qualities of the human species remain a blank
space on the scientific map. I doubt that discussions of ethics should rest
upon the freestanding assumptions of contemporary philosophers who have
evidently never given thought to the evolutionary origin and material
functioning of the human brain. In no other domain of the humanities is a union
with the natural sciences more urgently needed.

When the ethical dimension of human nature is at last fully opened to such
exploration, the innate epigenetic rules of moral reasoning will probably not
prove to be aggregated into simple instincts such as bonding, cooperativeness,
and altruism. Instead the rules will most probably turn out to be an ensemble
of many algorithms, whose interlocking activities guide the mind across a
landscape of nuanced moods and choices.

Such a prestructured mental world may at first seem too complicated to have
been created by autonomous genetic evolution alone. But all the evidence of
biology suggests that just this process was enough to spawn the millions of
species of life surrounding us. Each kind of animal is furthermore guided
through its life cycle by unique and often elaborate sets of instinctual
algorithms, many of which are beginning to yield to genetic and neurobiological
analyses. With all these examples before us, we may reasonably conclude that
human behavior originated the same way.

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
 The online version of this article appears in two parts. Click here to go to 
                                   part one.

                   A Scientific Approach to Moral Reasoning


MEANWHILE, the me'langes of moral reasoning employed by modern societies are,
to put the matter simply, a mess. They are chimeras, composed of odd parts
stuck together. Paleolithic egalitarian and tribalistic instincts are still
firmly installed. As part of the genetic foundation of human nature, they
cannot be replaced. In some cases, such as quick hostility to strangers and
competing groups, they have become generally ill adapted and persistently
dangerous. Above the fundamental instincts rise superstructures of arguments
and rules that accommodate the novel institutions created by cultural
evolution. These accommodations, which reflect the attempt to maintain order
and further tribal interests, have been too volatile to track by genetic
evolution; they are not yet in the genes.

Little wonder, then, that ethics is the most publicly contested of all
philosophical enterprises. Or that political science, which at its foundation
is primarily the study of applied ethics, is so frequently problematic. Neither
is informed by anything that would be recognizable as authentic theory in the
natural sciences. Both ethics and political science lack a foundation of
verifiable knowledge of human nature sufficient to produce cause-and-effect
predictions and sound judgments based on them. Surely closer attention must be
paid to the deep springs of ethical behavior. The greatest void in knowledge
for such a venture is the biology of moral sentiments. In time this subject can
be understood, I believe, by paying attention to the following topics:

* The definition of moral sentiments, first by precise descriptions from
experimental psychology and then by analysis of the underlying neural and
endocrine responses.


* The genetics of moral sentiments, most easily approached through measurements
of the heritability of the psychological and physiological processes of ethical
behavior, and eventually, with difficulty, through identification of the
prescribing genes.

* The development of moral sentiments as products of the interactions of genes
and the environment. Research is most effective when conducted at two levels:
the histories of ethical systems as part of the emergence of different
cultures, and the cognitive development of individuals living in a variety of
cultures. Such investigations are already well along in anthropology and
psychology. In the future they will be augmented by contributions from biology.

* The deep history of moral sentiments -- why they exist in the first place.
Presumably they contributed to survival and reproductive success during the
long periods of prehistoric time in which they genetically evolved.

From a convergence of these several approaches the true origin and meaning of
ethical behavior may come into focus. If so, a more certain measure can then be
taken of the strength and flexibility of the epigenetic rules composing the
various moral sentiments. From that knowledge it should be possible to adapt
ancient moral sentiments more wisely to the swiftly changing conditions of
modern life into which, willy-nilly and largely in ignorance, we have plunged.

Then new answers might be found to the truly important questions of moral
reasoning. How can the moral instincts be ranked? Which are best subdued and to
what degree? Which should be validated by law and symbol? How can precepts be
left open to appeal under extraordinary circumstances? In the new understanding
can be located the most effective means for reaching consensus. No one can
guess the exact form that agreements will take from one culture to the next.
The process, however, can be predicted with assurance. It will be democratic,
weakening the clash of rival religions and ideologies. History is moving
decisively in that direction, and people are by nature too bright and too
contentious to abide anything else. And the pace can be confidently predicted:
change will come slowly, across generations, because old beliefs die hard, even
when they are demonstrably false.

                            The Origins of Religion


THE same reasoning that aligns ethical philosophy with science can also inform
the study of religion. Religions are analogous to organisms. They have a life
cycle. They are born, they grow, they compete, they reproduce, and, in the
fullness of time, most die. In each of these phases religions reflect the human
organisms that nourish them. They express a primary rule of human existence:
Whatever is necessary to sustain life is also ultimately biological.

Successful religions typically begin as cults, which then increase in power and
inclusiveness until they achieve tolerance outside the circle of believers. At
the core of each religion is a creation myth, which explains how the world
began and how the chosen people -- those subscribing to the belief system --
arrived at its center. Often a mystery, a set of secret instructions and
formulas, is available to members who have worked their way to a higher state
of enlightenment. The medieval Jewish cabala, the trigradal system of
Freemasonry, and the carvings on Australian aboriginal spirit sticks are
examples of such arcana. Power radiates from the center, gathering converts and
binding followers to the group. Sacred places are designated, where the gods
can be importuned, rites observed, and miracles witnessed.

The devotees of the religion compete as a tribe with those of other religions.
They harshly resist the dismissal of their beliefs by rivals. They venerate
self-sacrifice in defense of the religion.

The tribalistic roots of religion are similar to those of moral reasoning and
may be identical. Religious rites, such as burial ceremonies, are very old. It
appears that in the late Paleolithic period in Europe and the Middle East
bodies were sometimes placed in shallow graves, accompanied by ocher or
blossoms; one can easily imagine such ceremonies performed to invoke spirits
and gods. But, as theoretical deduction and the evidence suggest, the primitive
elements of moral behavior are far older than Paleolithic ritual. Religion
arose on a foundation of ethics, and it has probably always been used in one
manner or another to justify moral codes.

The formidable influence of the religious drive is based on far more, however,
than just the validation of morals. A great subterranean river of the mind, it
gathers strength from a broad spread of tributary emotions. Foremost among them
is the survival instinct. "Fear," as the Roman poet Lucretius said, "was the
first thing on earth to make the gods." Our conscious minds hunger for a
permanent existence. If we cannot have everlasting life of the body, then
absorption into some immortal whole will serve. Anything will serve, as long as
it gives the individual meaning and somehow stretches into eternity that swift
passage of the mind and spirit lamented by Saint Augustine as the short day of
time.

The understanding and control of life is another source of religious power.
Doctrine draws on the same creative springs as science and the arts, its aim
being the extraction of order from the mysteries and tumult of the material
world. To explain the meaning of life it spins mythic narratives of the tribal
history, populating the cosmos with protective spirits and gods. The existence
of the supernatural, if accepted, testifies to the existence of that other
world so desperately desired.

Religion is also mightily empowered by its principal ally, tribalism. The
shamans and priests implore us, in somber cadence, Trust in the sacred rituals,
become part of the immortal force, you are one of us. As your life unfolds,
each step has mystic significance that we who love you will mark with a solemn
rite of passage, the last to be performed when you enter that second world,
free of pain and fear.

If the religious mythos did not exist in a culture, it would quickly be
invented, and in fact it has been invented everywhere, thousands of times
through history. Such inevitability is the mark of instinctual behavior in any
species, which is guided toward certain states by emotion-driven rules of
mental development. To call religion instinctive is not to suppose that any
particular part of its mythos is untrue -- only that its sources run deeper
than ordinary habit and are in fact hereditary, urged into existence through
biases in mental development that are encoded in the genes.

Such biases are a predictable consequence of the brain's genetic evolution. The
logic applies to religious behavior, with the added twist of tribalism. There
is a hereditary selective advantage to membership in a powerful group united by
devout belief and purpose. Even when individuals subordinate themselves and
risk death in a common cause, their genes are more likely to be transmitted to
the next generation than are those of competing groups who lack comparable
resolve.

The mathematical models of population genetics suggest the following rule in
the evolutionary origin of such altruism: If the reduction in survival and
reproduction of individuals owing to genes for altruism is more than offset by
the increased probability of survival of the group owing to the altruism, then
altruism genes will rise in frequency throughout the entire population of
competing groups. To put it as concisely as possible: the individual pays, his
genes and tribe gain, altruism spreads.

                            Ethics and Animal Life


LET me now suggest a still deeper significance of the empiricist theory of the
origin of ethics and religion. If empiricism were disproved, and
transcendentalism compellingly upheld, the discovery would be quite simply the
most consequential in human history. That is the burden laid upon biology as it
draws close to the humanities.

The matter is still far from resolved. But empiricism, as I have argued, is
well supported thus far in the case of ethics. The objective evidence for or
against it in religion is weaker, but at least still consistent with biology.
For example, the emotions that accompany religious ecstasy clearly have a
neurobiological source. At least one form of brain disorder is associated with
hyperreligiosity, in which cosmic significance is given to almost everything,
including trivial everyday events. One can imagine the biological construction
of a mind with religious beliefs, although that alone would not disprove the
logic of transcendentalism, or prove the beliefs themselves to be untrue.

Equally important, much if not all religious behavior could have arisen from
evolution by natural selection. The theory fits -- crudely. The behavior
includes at least some aspects of belief in gods. Propitiation and sacrifice,
which are near-universals of religious practice, are acts of submission to a
dominant being. They reflect one kind of dominance hierarchy, which is a
general trait of organized mammalian societies. Like human beings, animals use
elaborate signals to advertise and maintain their rank in the hierarchy. The
details vary among species but also have consistent similarities across the
board, as the following two examples will illustrate.

In packs of wolves the dominant animal walks erect and "proud," stiff-legged
and deliberate, with head, tail, and ears up, and stares freely and casually at
others. In the presence of rivals the dominant animal bristles its pelt while
curling its lips to show teeth, and it takes first choice in food and space. A
subordinate uses opposite signals. It turns away from the dominant individual
while lowering its head, ears, and tail, and it keeps its fur sleek and its
teeth covered. It grovels and slinks, and yields food and space when
challenged.

In a troop of rhesus monkeys the alpha male is remarkably similar in mannerisms
to a dominant wolf. He keeps his head and tail up, and walks in a deliberate,
"regal" manner while casually staring at others. He climbs objects to maintain
height above his rivals. When challenged he stares hard at the opponent with
mouth open -- signaling aggression, not surprise -- and sometimes slaps the
ground with open palms to signal his readiness to attack. The male or female
subordinate affects a furtive walk, holding its head and tail down, turning
away from the alpha and other higher-ranked individuals. It keeps its mouth
shut except for a fear grimace, and when challenged makes a cringing retreat.
It yields space and food and, in the case of males, estrous females.

My point is this: Behavioral scientists from another planet would notice
immediately the parallels between animal dominance behavior on the one hand and
human obeisance to religious and civil authority on the other. They would point
out that the most elaborate rites of obeisance are directed at the gods, the
hyperdominant if invisible members of the human group. And they would conclude,
correctly, that in baseline social behavior, not just in anatomy, Homo sapiens
has only recently diverged in evolution from a nonhuman primate stock.

Countless studies of animal species, whose instinctive behavior is unobscured
by cultural elaboration, have shown that membership in dominance orders pays
off in survival and lifetime reproductive success. That is true not just for
the dominant individuals but for the subordinates as well. Membership in either
class gives animals better protection against enemies and better access to
food, shelter, and mates than does solitary existence. Furthermore,
subordination in the group is not necessarily permanent. Dominant individuals
weaken and die, and as a result some of the underlings advance in rank and
appropriate more resources.

Modern human beings are unlikely to have erased the old mammalian genetic
programs and devised other means of distributing power. All the evidence
suggests that they have not. True to their primate heritage, people are easily
seduced by confident, charismatic leaders, especially males. That
predisposition is strong in religious organizations. Cults form around such
leaders. Their power grows if they can persuasively claim special access to the
supremely dominant, typically male figure of God. As cults evolve into
religions, the image of the Supreme Being is reinforced by myth and liturgy. In
time the authority of the founders and their successors is graven in sacred
texts. Unruly subordinates, known as "blasphemers," are squashed.

The symbol-forming human mind, however, never remains satisfied with raw, apish
feeling in any emotional realm. It strives to build cultures that are maximally
rewarding in every dimension. Ritual and prayer permit religious believers to
be in direct touch with the Supreme Being; consolation from coreligionists
softens otherwise unbearable grief; the unexplainable is explained; and an
oceanic sense of communion with the larger whole is made possible.

Communion is the key, and hope rising from it is eternal; out of the dark night
of the soul arises the prospect of a spiritual journey to the light. For a
special few the journey can be taken in this life. The mind reflects in certain
ways in order to reach ever higher levels of enlightenment, until finally, when
no further progress is possible, it enters a mystical union with the whole.
Within the great religions such enlightenment is expressed by Hindu samadhi,
Buddhist Zen satori, Sufi fana, and Pentecostal Christian rebirth. Something
like it is also experienced by hallucinating preliterate shamans. What all
these celebrants evidently feel (as I felt once, to some degree, as a reborn
evangelical) is hard to put in words, but Willa Cather came as close as
possible in a single sentence. In My Antonia her fictional narrator says, "That
is happiness; to be dissolved into something complete and great."


Of course that is happiness -- to find the godhead, or to enter the wholeness
of nature, or otherwise to grasp and hold on to something ineffable, beautiful,
and eternal. Millions seek it. They feel otherwise lost, adrift in a life
without ultimate meaning. They enter established religions, succumb to cults,
dabble in New Age nostrums. They push The Celestine Prophecy and other junk
attempts at enlightenment onto the best-seller lists.

Perhaps, as I believe, these phenomena can all eventually be explained as
functions of brain circuitry and deep genetic history. But this is not a
subject that even the most hardened empiricist should presume to trivialize.
The idea of mystical union is an authentic part of the human spirit. It has
occupied humanity for millennia, and it raises questions of utmost seriousness
for transcendentalists and scientists alike. What road, we ask, was traveled,
what destination reached, by the mystics of history?

                       Theology Moves Toward Abstraction


FOR many, the urge to believe in transcendental existence and immortality is
overpowering. Transcendentalism, especially when reinforced by religious faith,
is psychically full and rich; it feels somehow right. By comparison, empiricism
seems sterile and inadequate. In the quest for ultimate meaning the
transcendentalist route is much easier to follow. That is why, even as
empiricism is winning the mind, transcendentalism continues to win the heart.
Science has always defeated religious dogma point by point when differences
between the two were meticulously assessed. But to no avail. In the United
States 16 million people belong to the Southern Baptist denomination, the
largest favoring a literal interpretation of the Christian Bible, but the
American Humanist Association, the leading organization devoted to secular and
deistic humanism, has only 5,000 members.

Still, if history and science have taught us anything, it is that passion and
desire are not the same as truth. The human mind evolved to believe in gods. It
did not evolve to believe in biology. Acceptance of the supernatural conveyed a
great advantage throughout prehistory, when the brain was evolving. Thus it is
in sharp contrast to the science of biology, which was developed as a product
of the modern age and is not underwritten by genetic algorithms. The
uncomfortable truth is that the two beliefs are not factually compatible. As a
result, those who hunger for both intellectual and religious truth face
disquieting choices.

Meanwhile, theology tries to resolve the dilemma by evolving, sciencelike,
toward abstraction. The gods of our ancestors were divine human beings. The
Egyptians represented them as Egyptian (often with body parts of Nilotic
animals), and the Greeks represented them as Greek. The great contribution of
the Hebrews was to combine the entire pantheon into a single person, Yahweh (a
patriarch appropriate to desert tribes), and to intellectualize his existence.
No graven images were allowed. In the process, they rendered the divine
presence less tangible. And so in biblical accounts it came to pass that no
one, not even Moses approaching Yahweh in the burning bush, could look upon his
face. In time the Jews were prohibited from even pronouncing his true full
name. Nevertheless, the idea of a theistic God, omniscient, omnipotent, and
closely involved in human affairs, has persisted to this day as the dominant
religious image of Western culture.

During the Enlightenment a growing number of liberal Judeo-Christian
theologians, wishing to accommodate theism to a more rationalist view of the
material world, moved away from God as a literal person. Baruch Spinoza, the
pre-eminent Jewish philosopher of the seventeenth century, visualized the deity
as a transcendent substance present everywhere in the universe. Deus sive
natura, "God or nature," he declared, they are interchangeable. For his
philosophical pains he was banished from his synagogue under a comprehensive
anathema, combining all the curses in the book. The risk of heresy
notwithstanding, the depersonalization of God has continued steadily into the
modern era. For Paul Tillich, one of the most influential Protestant
theologians of the twentieth century, the assertion of the existence of
God-as-person is not false; it is just meaningless. Among many of the most
liberal contemporary thinkers the denial of a concrete divinity takes the form
of "process theology." Everything in this most extreme of ontologies is part of
a seamless and endlessly complex web of unfolding relationships. God is
manifest in everything.

Scientists, the roving scouts of the empiricist movement, are not immune to the
idea of God. Those who favor it often lean toward some form of process
theology. They ask this question: When the real world of space, time, and
matter is well enough known, will that knowledge reveal the Creator's presence?
Their hopes are vested in the theoretical physicists who pursue the final
theory, the Theory of Everything, T.O.E., a system of interlocking equations
that describe all that can be learned of the forces of the physical universe.
T.O.E. is a "beautiful" theory, as Steven Weinberg has called it in his
important book Dreams of a Final Theory -- beautiful because it will be
elegant, expressing the possibility of unending complexity with minimal laws;
and symmetrical, because it will hold invariant through all space and time; and
inevitable, meaning that once it is stated, no part can be changed without
invalidating the whole. All surviving subtheories can be fitted into it
permanently, in the manner described by Einstein in his own contribution, the
General Theory of Relativity. "The chief attraction of the theory," Einstein
said, "lies in its logical completeness. If a single one of the conclusions
drawn from it proves wrong, it must be given up; to modify it without
destroying the whole structure seems to be impossible."

The prospect of a final theory by the most mathematical of scientists might
seem to signal the approach of a new religious awakening. Stephen Hawking,
yielding to the temptation in A Brief History of Time (1988), declared that
this scientific achievement "would be the ultimate triumph of human reason --
for then we would know the mind of God."

                           A Hunger For Spirituality


THE essence of humanity's spiritual dilemma is that we evolved genetically to
accept one truth and discovered another. Can we find a way to erase the
dilemma, to resolve the contradictions between the transcendentalist and
empiricist world views?

Unfortunately, in my view, the answer is no. Furthermore, the choice between
the two is unlikely to remain arbitrary forever. The assumptions underlying
these world views are being tested with increasing severity by cumulative
verifiable knowledge about how the universe works, from atom to brain to
galaxy. In addition, the harsh lessons of history have taught us that one code
of ethics is not always as good -- or at least not as durable -- as another.
The same is true of religions. Some cosmologies are factually less correct than
others, and some ethical precepts are less workable.

Human nature is biologically based, and it is relevant to ethics and religion.
The evidence shows that because of its influence, people can readily be
educated to only a narrow range of ethical precepts. They flourish within
certain belief systems and wither in others. We need to know exactly why.

To that end I will be so presumptuous as to suggest how the conflict between
the world views will most likely be settled. The idea of a genetic,
evolutionary origin of moral and religious beliefs will continue to be tested
by biological studies of complex human behavior. To the extent that the sensory
and nervous systems appear to have evolved by natural selection, or at least
some other purely material process, the empiricist interpretation will be
supported. It will be further supported by verification of gene-culture
coevolution, the essential process postulated by scientists to underlie human
nature by linking changes in genes to changes in culture.

Now consider the alternative. To the extent that ethical and religious
phenomena do not appear to have evolved in a manner congenial to biology, and
especially to the extent that such complex behavior cannot be linked to
physical events in the sensory and nervous systems, the empiricist position
will have to be abandoned and a transcendentalist explanation accepted.

For centuries the writ of empiricism has been spreading into the ancient domain
of transcendentalist belief, slowly at the start but quickening in the
scientific age. The spirits our ancestors knew intimately fled first the rocks
and trees and then the distant mountains. Now they are in the stars, where
their final extinction is possible. But we cannot live without them. People
need a sacred narrative. They must have a sense of larger purpose, in one form
or another, however intellectualized. They will refuse to yield to the despair
of animal mortality. They will continue to plead, in company with the psalmist,
Now Lord, what is my comfort? They will find a way to keep the ancestral
spirits alive.

If the sacred narrative cannot be in the form of a religious cosmology, it will
be taken from the material history of the universe and the human species. That
trend is in no way debasing. The true evolutionary epic, retold as poetry, is
as intrinsically ennobling as any religious epic. Material reality discovered
by science already possesses more content and grandeur than all religious
cosmologies combined. The continuity of the human line has been traced through
a period of deep history a thousand times as old as that conceived by the
Western religions. Its study has brought new revelations of great moral
importance. It has made us realize that Homo sapiens is far more than an
assortment of tribes and races. We are a single gene pool from which
individuals are drawn in each generation and into which they are dissolved the
next generation, forever united as a species by heritage and a common future.
Such are the conceptions, based on fact, from which new intimations of
immortality can be drawn and a new mythos evolved.

Which world view prevails, religious transcendentalism or scientific
empiricism, will make a great difference in the way humanity claims the future.
While the matter is under advisement, an accommodation can be reached if the
following overriding facts are realized. Ethics and religion are still too
complex for present-day science to explain in depth. They are, however, far
more a product of autonomous evolution than has hitherto been conceded by most
theologians. Science faces in ethics and religion its most interesting and
possibly most humbling challenge, while religion must somehow find the way to
incorporate the discoveries of science in order to retain credibility. Religion
will possess strength to the extent that it codifies and puts into enduring,
poetic form the highest values of humanity consistent with empirical knowledge.
That is the only way to provide compelling moral leadership. Blind faith, no
matter how passionately expressed, will not suffice. Science, for its part,
will test relentlessly every assumption about the human condition and in time
uncover the bedrock of moral and religious sentiments.

The eventual result of the competition between the two world views, I believe,
will be the secularization of the human epic and of religion itself. However
the process plays out, it demands open discussion and unwavering intellectual
rigor in an atmosphere of mutual respect.

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

  • Continue Reading
  • Jump to Comments
  • About the Author

  • 
     
  • 
     
  •  
  •  
  •   
  •  
  •  
  •  

Latest Video

[thumb_wide]

The Marathon Runner of Mumbai

Abbas Sheikh is a jewelry polisher who became a top competitor by running in
his spare time. This is what the sport means to him.

  • Nadine Ajaka
  • 3:27 PM ET
  •  

Latest Slideshow

[thumb_wide] Peter Garritano

In Photos: Inside the Internet

Photographs of what “the cloud” actually looks like

  • Emily Anne Epstein
  • Jan 5, 2016
  •  

Most Popular

Presented by

  • Mark Makela / Reuters

    Bill Cosby and His Enablers

      □ Ta-Nehisi Coates

    Even victims of discrimination can look away from—and thereby enable—other
    forms of violence.

    Long before the Black Lives Matter movement raised the problem of immoral
    police (and vigilante) violence, African Americans grappled with its
    reality and the seemingly impenetrable logic which undergirds it. The mind
    reels at the justifications proffered for killing a 12-year-old child, or
    the calculation that finds an officer raining blows on someone’s
    grandmother, or the science that encourages a man to fire a gun over his
    shoulder and into a crowd.

      

    Fiction undergirds all of these acts—of furtive movements, reasonable fear,
    and therapy through violence. So strong is the power of the legitimizing
    narrative, that even those who are victims of these violent fictions are
    rarely deterred from crafting justifying fictions of their own. In the 19th
    and 20th century, the old discriminations against white ethnics—“no Irish
    need apply”—did very little to prevent those same white ethnics from
    engaging in anti-black racism.  Yet for a starker example, it may well
    better to look closer to home.

      
    Continue Reading
  • Reuters

    What Makes a Joke ‘Transphobic’?

      □ Spencer Kornhaber

    Ricky Gervais doesn’t understand why people are peeved at him. It’s pretty
    simple, though.

    If there was a theme to Ricky Gervais’s performance at Sunday’s Golden
    Globe Awards, it was that pop culture’s purported “transgender moment” is
    awfully funny. He pretended that he thought Eddie Redmayne, who plays a
    transgender woman in The Danish Girl, was actually female. He speculated
    about what Jeffrey Tambor does with his testicles on Transparent. And
    toward the beginning of his monologue, Gervais said that he himself had
    changed a lot in a year, “but not as much as Bruce Jenner, obviously.”

      

    There was a short pause. Some laughter from the audience. Then a follow-up
    joke.

      

    “She became a role model for trans people everywhere, showing great bravery
    in breaking down barriers and destroying stereotypes. She didn’t do a lot
    for women drivers, but you can’t have everything, can ya?”

      
    Continue Reading
  • Jason Lee / Reuters

    Consciousness Is Not Mysterious

      □ Michael Graziano

    It’s just the brain describing itself—to itself.  

    When Isaac Newton was 17 years old, he performed a series of experiments
    with prisms and light beams. Within weeks he discovered the scientific
    explanation for color, invented the reflecting telescope, proposed the
    particle theory of light, and deduced that the human eye contained three
    receptor types corresponding to the three primary colors. Not bad for a
    teen.

      

    Newton’s insights were not easily accepted. At the time, the prevailing
    theory of color was metaphysical. White light was thought to be pure,
    heavenly, and scrubbed of all contaminants, whereas colored light was
    contaminated by the worldly surfaces it touched. To scholars, the exact
    process by which white light became dirtied was a philosophical hard
    problem worthy of debate.

      
    Continue Reading
  • Daybreak Game Company

    When a Video-Game World Ends

      □ Will Partin

    What happens when the vast universes in massively multiplayer online games
    go offline?

    In English, the word “apocalypse”—ety. Greek, n. apo (un-) + kaluptein
    (-veil)—has three non-exclusive meanings. The first and most common is
    simply the end of the world, whether by divine punishment or whatever
    transpires in movies directed by Roland Emmerich. The second is any form of
    calamity, representational or real, man-made or no, that resembles the end
    of the world, like the 2010 Haitian earthquake, Chernobyl, or the movies
    directed by Roland Emmerich themselves. The third is what the Greeks
    intended apocalypse to mean: the revelation of knowledge through profound
    disruption, which is why the final book of the New Testament is called
    “Revelations” (composed, it is thought, to reassure Christians during their
    widespread persecution by the Roman emperor, Domitian). In other words, the
    apocalypse either is the end, looks like the end, or helps us understand
    the end.

      
    Continue Reading
  • 2 / Riko Pictures / Ocean / Corbis

    Can You Spot a Liar?

      □ Olga Khazan

    Probably not. But here are some techniques grifters use, courtesy of Maria
    Konnikova and her new book about con artists.

    In November, I came across a story that made absolutely no sense to me. A
    33-year-old consultant named Niall Rice gave $718,000, little by little, to
    two Manhattan psychics who promised to reunite him with an old flame. How
    could someone be so gullible? Rice himself didn’t even seem to know: “I
    just got sucked in,” he told The New York Times later.

      

    As it turns out, it’s much easier to fall for these types of cons than many
    people think. As Maria Konnikova, a psychologist and New Yorker
    contributor, explains in her new book, The Confidence Game, grifters
    manipulate human emotions in genius (and evil) ways, striking right when we
    feel lovelorn or otherwise emotionally vulnerable. I recently spoke with
    Konnikova about cons, why they happen, and if there’s any way to avoid
    becoming a fraudster’s next target. A lightly edited version of our
    conversation follows.

      
    Continue Reading
  • Stephanie Keith / Reuters

    What Becomes of Lottery Winners?

      □ Bourree Lam

    Millions are buying Powerball tickets assuming that winning will bring them
    a prosperous, work-free life, but research suggests they shouldn't be so
    certain.

    This week, many Americans will be buying into the same dream: winning the
    unprecedentedly large $1.3 billion Powerball jackpot on Wednesday night.
    Since last week, when the jackpot had accrued to over $500 million,
    Powerball tickets have been reportedly flying off bodega and
    convenience-store counters. The odds of winning remain 1 in 292 million
    —that’s why the lottery is sometimes called a “stupidity tax”—but a
    ticket’s $2 pricetag does make it a low-risk impulse buy. (Alex Tabarrok,
    over at Marginal Revolution, suggests that those who participate should buy
    tickets early in order to enjoy their real value—the pleasure of
    anticipation—for longer).

      

    Many people are hoping to acquire this tremendous windfall, but is what
    they’re after something that will actually make them happy? Anecdotes about
    how winning the lottery can be bad luck abound—a winning ticket has led
    some “lucky” winners into bankruptcy, or worse. But there’s also the
    possibility that all of the lottery winners who are living comfortably
    don’t make headlines.

      
    Continue Reading
  • Brian Snyder / Reuters

    What If Bernie Sanders Is the Democrats' Best Bet?

      □ David A. Graham

    The Vermont senator now argues that he’s more electable against a
    Republican than his leading rival.

    If you’d told most Americans a year ago that Bernie Sanders would be a
    serious threat to Hillary Clinton in January 2016, they probably would have
    laughed. (Or asked who Sanders was.) If you’d told them that Sanders would
    be arguing that he was a better candidate than Clinton because he was more
    electable, the reaction would have been even more incredulous. She was
    cautious, sure, and a bit more conservative than some Democrats, but surely
    she was more palatable to voters than an acerbic democratic socialist from
    Vermont.

      

    That is, however, exactly the state of the Democratic race on January 11.
    An NBC News/Wall Street Journal poll released over the weekend tells the
    story. In Iowa, Clinton leads Sanders among likely voters by just three
    points. In New Hampshire, where he has mostly kept a small lead for months,
    he’s up four. The Sanders campaign blasted out the results to reporters
    Sunday under the subject line “Electability Matters.” Speaking on This Week
    , Sanders said: “If people are concerned about electability—and Democrats
    should be very concerned because we certainly don’t want to see some
    right-wing extremist in the White House—Bernie Sanders is the candidate.”

     
    Continue Reading
  • Rick Bowmer / AP

    The Decline of the Bundy Rebellion

      □ David A. Graham

    As the Oregon occupation stretches into its 11^th day, even local residents
    who are critical of the federal government are stepping up calls for the
    militia to leave.

    What did Ammon and Ryan Bundy learn from their father's 2014 standoff in
    Nevada? Not enough, apparently.

      

    When Cliven Bundy started his showdown with the Bureau of Land Management,
    he quickly attracted a slew of high-profile backers: Republican Senators
    Dean Heller, Ted Cruz, and Rand Paul; Texas Governor Rick Perry; and Texas
    Attorney General Greg Abbott, who has since become governor. But Bundy’s
    hand was weak—after all, anyone who claims he isn’t governed by the
    Constitution and refuses to pay land fees for decades has a weak claim, to
    say nothing of the jarring image of armed men holding off law enforcement.
    Bundy overplayed the weak hand, too, spouting off about “the Negro.” His
    backers fled and the standoff ended—though he has continued to graze his
    cattle on federal lands and still hasn’t paid the fees he owes, which could
    hold clues for how the Oregon standoff might end.

     
    Continue Reading
  • AP/The Atlantic

    What ISIS Really Wants

      □ Graeme Wood

    The Islamic State is no mere collection of psychopaths. It is a religious
    group with carefully considered beliefs, among them that it is a key agent
    of the coming apocalypse. Here’s what that means for its strategy—and for
    how to stop it.

    What is the Islamic State?

      

    Where did it come from, and what are its intentions? The simplicity of
    these questions can be deceiving, and few Western leaders seem to know the
    answers. In December, The New York Times published confidential comments by
    Major General Michael K. Nagata, the Special Operations commander for the
    United States in the Middle East, admitting that he had hardly begun
    figuring out the Islamic State’s appeal. “We have not defeated the idea,”
    he said. “We do not even understand the idea.” In the past year, President
    Obama has referred to the Islamic State, variously, as “not Islamic” and as
    al-Qaeda’s “jayvee team,” statements that reflected confusion about the
    group, and may have contributed to significant strategic errors.

     
    Continue Reading
  • Kim Kyung Hoon / Reuters

    Gun Control Around the World: A Primer

      □ Jonathan Masters

    Lessons from Canada to Japan

    The debate over gun control in the United States has waxed and waned over
    the years, stirred by a series of mass killings by gunmen in civilian
    settings. In particular, the killing of 20 schoolchildren in Newtown,
    Connecticut, in December 2012 fueled a national discussion over gun laws
    and calls by the Obama administration to limit the availability of
    military-style weapons. However, compromise legislation that would have
    banned semiautomatic assault weapons and expanded background checks was
    defeated in the Senate in 2013, despite extensive public support.

      

    Gun-control advocates sought to rekindle the debate following another
    string of deadly mass shootings in 2015, including the killing of nine
    people at a church in Charleston, South Carolina, and 14 at a community
    center in San Bernardino, California. These advocates often highlight the
    stricter gun laws and lower incidence of gun violence in several other
    democracies, like Japan and Australia, but many others say this correlation
    proves little and note that rates of gun crime in the United States have
    plunged over the last two decades.

     
    Continue Reading
  • This Is What It's Like to Read Lips

      □ Nadine Ajaka

    On the messy and imprecise process of using one sense to do the work of
    another

    Watch Video
  • The Most Powerful Images of 2015

      □ Greyson Korhonen and Alan Taylor

    A selection of the year's best photos

    Watch Video
  • A Gym for Mindfulness

      □ James Hamblin, Nicolas Pollock, and Jaclyn Skurie

    Drop in and meditate, any time.

    Watch Video

More Popular Stories
Show Comments

Subscribe

Get 10 issues a year and save 65% off the cover price.

 
[                    ] [                    ] [                    ]
[                    ]
[State                 ]
[          ] [United States       ] [Order Now]
Fraud Alert regarding The Atlantic

Newsletters+

  • The Atlantic
  • [ ] The Atlantic Daily
  • [ ] This Week
  • [ ] This Month
  • [ ] New Photo Galleries
  • [ ] Top Videos This Week

  • CityLab
  • [ ] Today’s Top Stories
  • [ ] This Week's Most Popular Stories
  • [*] I want to receive updates from partners and sponsors.
  • 
  • [Sign up]

Follow+

  • Facebook
  • Twitter
  • LinkedIn
  • Tumblr
  • Pinterest
  • RSS
  • App Store

About+

  • Masthead
  • FAQ
  • Press
  • Jobs
  • Shop
  • Books
  • Emporium

  • Contact Us
  • Privacy Policy
  • Advertise
  • Advertising Guidelines
  • Terms and Conditions
  • Subscriber Help
  • Site Map

Copyright © 2016 by The Atlantic Monthly Group. All Rights Reserved.

Close
Skip Ad >
*
*
[p]
*
* 
